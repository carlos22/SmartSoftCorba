//--------------------------------------------------------------------------
// Code generated by the SmartSoft MDSD Toolchain Version 0.10.0
// The SmartSoft Toolchain has been developed by:
//
// ZAFH Servicerobotic Ulm
// Christian Schlegel (schlegel@hs-ulm.de)
// University of Applied Sciences
// Prittwitzstr. 10
// 89075 Ulm (Germany)
//
// Information about the SmartSoft MDSD Toolchain is available at:
// smart-robotics.sourceforge.net
//
// This file is generated once. Modify this file to your needs.
// If you want the toolchain to re-generate this file, please
// delete it before running the code generator.
//--------------------------------------------------------------------------

//------------------------------------------------------------------------
//
//  Copyright (C) 2010 Manuel Wopfner
//
//        wopfner@hs-ulm.de
//
//        Christian Schlegel (schlegel@hs-ulm.de)
//        University of Applied Sciences
//        Prittwitzstr. 10
//        89075 Ulm (Germany)
//
//  This file is part of the "CommManipulatorObjects".
//
//  This library is free software; you can redistribute it and/or
//  modify it under the terms of the GNU Lesser General Public
//  License as published by the Free Software Foundation; either
//  version 2.1 of the License, or (at your option) any later version.
//
//  This library is distributed in the hope that it will be useful,
//  but WITHOUT ANY WARRANTY; without even the implied warranty of
//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
//  Lesser General Public License for more details.
//
//  You should have received a copy of the GNU Lesser General Public
//  License along with this library; if not, write to the Free Software
//  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
//--------------------------------------------------------------------------

#ifndef _COMM_COMMVISIONOBJECTS_COMMTOFIMAGE_HH
#define _COMM_COMMVISIONOBJECTS_COMMTOFIMAGE_HH

#include <string>

// include files of classes
#include <CommVisionObjects/gen/structToFImageParametersC.hh>

// include header-files of included communication objects
#include <CommBasicObjects/commBaseState.hh>
#include <CommBasicObjects/commPose3d.hh>

// include enums


// include client-side file generated by IDL compiler
#include "CommVisionObjects/gen/smartCommToFImageC.hh"

namespace CommVisionObjects
{

/**
 * A constant ToF image.
 * Constant means that pixel values and the image size can be read but cannot be changed.
 * Clients may not lock the image (the image is constant, so there is no locking needed).
 */
class CommToFImage
{
private:
	arma::mat robot_mat;
	arma::mat world_mat;


protected:
	CommVisionObjectsIDL::CommToFImage idl_CommToFImage;

public:
	CommToFImage()
	{
	}

	CommToFImage(const CommVisionObjectsIDL::CommToFImage &obj) :
		idl_CommToFImage(obj)
	{
	}

	virtual ~CommToFImage()
	{
	}

	void get(CORBA::Any &a) const;
	void set(const CORBA::Any &a);

	inline const CommVisionObjectsIDL::CommToFImage &get() const
	{
		return idl_CommToFImage;
	}

	inline void set(const CommVisionObjectsIDL::CommToFImage &obj)
	{
		idl_CommToFImage = obj;
	}

	static inline std::string identifier(void)
	{
		return "CommVisionObjects::CommToFImage";
	}






	//
	// user interfaces
	CommToFImage(uint32_t width, uint32_t height) {

		set_parameters(width, height);


	}

	/**
	 * Get the pose of the sensor relative to the robot coordinate system.
	 */
	inline CommBasicObjects::CommPose3d get_sensor_pose() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->sensor_pose;
		return idl_CommToFImage.sensor_pose;
	}

	/**
	 * Get the state of the base.
	 */
	inline CommBasicObjects::CommBaseState get_base_state() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->base_state;
		return idl_CommToFImage.baseState;
	}

	/**
	 * Get the width of the ToF image in pixels.
	 */
	inline uint32_t get_width() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->width;
		return idl_CommToFImage.parameter.width;
	}

	/**
	 * Get the height of the ToF image in pixels.
	 */
	inline uint32_t get_height() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->height;
		return idl_CommToFImage.parameter.height;
	}

	/**
	 * Get the minimal distance the sensor works.
	 */
	inline double_t get_min_distance(const double_t unit = 0.001) const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->min_distance * 0.001 / unit;
		return idl_CommToFImage.min_distance * 0.001 / unit;
	}

	/**
	 * Get the maximal distance the sensor works.
	 */
	inline double_t get_max_distance(const double_t unit = 0.001) const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->max_distance * 0.001 / unit;
		return idl_CommToFImage.max_distance * 0.001 / unit;
	}

	/**
	 * Get the opening angle of the camera in x-axis [rad].
	 * It is expected that the opening angle in positive and negative direction is the same.
	 */
	inline double_t get_opening_angle_x_axis() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->opening_angle_x_axis;
		return idl_CommToFImage.opening_angle_x_axis;
	}

	/**
	 * Get the opening angle of the camera in y-axis [rad].
	 * It is expected that the opening angle in positive and negative direction is the same.
	 */
	inline double_t get_opening_angle_y_axis() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->opening_angle_y_axis;
		return idl_CommToFImage.opening_angle_y_axis;
	}

	/**
	 * Get the integration time which was used for capturing the image.
	 */
	inline double_t get_integration_time() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->integration_time;
		return idl_CommToFImage.integration_time;
	}

	/**
	 * Get the modulation frequency which was used for capturing the image.
	 */
	inline double_t get_modulation_frequency() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->modulation_frequency;
		return idl_CommToFImage.modulation_frequency;
	}

	/**
	 * Return the size of the whole ToF image (incl. image parameters etc.) in memory in bytes.
	 */
	/*
	inline uint32_t get_size() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->size;
		return idl_CommToFImage.parameter.size;
	}
	*/


	/**
	 * Return the size of one of the ToF images in width*height
	 */
	inline uint32_t get_image_size() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->image_size;
		return idl_CommToFImage.parameter.image_size;
	}

	/**
	 * Check if the image data is valid.
	 */
	inline bool is_data_valid() const {
		//return (shm) && reinterpret_cast<const ToFImageParameters*> (shm)->data_valid;
		return idl_CommToFImage.is_valid;
	}

	inline void set_data_valid(bool value) {
		idl_CommToFImage.is_valid = value;
	}

	/**
	 * Returns the server sided sequence counter of this image.
	 * Use it to see if your client drops frames.
	 */
	inline ulong get_sequence_counter() const {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->seq_count;
		return idl_CommToFImage.seq_count;
	}

	inline void set_sequence_counter(ulong s) {
		//return reinterpret_cast<const ToFImageParameters*> (shm)->seq_count;
		idl_CommToFImage.seq_count = s;
	}

	/**
	 * Returns the measurement accuracy for a given pixel.
	 */
	inline double_t get_measurement_accuracy(const uint32_t posX, const uint32_t posY) {
		uint32_t offset = (posY * get_width()) + posX;
		float intensity = *(get_intensities() + offset);
		float amplitude = *(get_amplitudes() + offset);
		return (get_max_distance(1) / CommToFImage::SQRT_EIGHT) * (sqrt(intensity)) / (2 * amplitude);
	}

	/*
	 * partly from http://www.ros.org/doc/api/new_point_cloud_mapping/html/nearest_8h-source.html
	 *
	 * void filterJumpEdges(const new_point_cloud::FastPointCloud &points,
	 *		new_point_cloud::FastPointCloud &points_filtered, int k, int width,
	 *		int height, double min_angle, double max_angle,
	 *		const new_point_cloud::Point &viewpoint)
	 *
	 * Filter jump edges in an organized point cloud dataset (e.g., acquired using TOF or dense stereo, etc).
	 *
	 * the input point cloud size is assumed to have (width*height) number of points, in order!
	 *
	 * Parameters:
	 *		p_x					the x coordinate of the point in the ToF image
	 *		p_y					the y coordinate of the point in the ToF image
	 *    	k					the windowing factor (i.e., how many pixels in the depth image in all directions should the neighborhood of a point contain)
	 *    	min_angle 			the minimum angle allowed between the viewpoint ray and the line formed by two subsequent points(used for filtering jump edge data)
	 *    	max_angle 			the maximum angle allowed between the viewpoint ray and the line formed by two subsequent points(used for filtering jump edge data)
	 */
	inline bool is_point_a_jump_edge(unsigned int p_x, unsigned int p_y, int k, double min_angle, double max_angle) const
	{
			const int width = get_width();
			const int height = get_height();
			const float* coordinates = get_coordinates();
			const double viewpoint_x = get_sensor_pose().get_x(1.0);
			const double viewpoint_y = get_sensor_pose().get_y(1.0);
			const double viewpoint_z = get_sensor_pose().get_z(1.0);

//			std::cout << "viewpoint_x: " << viewpoint_x << " viewpoint_y: " << viewpoint_y << " viewpoint_z: " << viewpoint_z << std::endl;
			// Obtain the <u,v> pixel values
			uint32_t u = p_y;//i / width;
			uint32_t v = p_x;//i % width;
			int i = p_y * width + p_x; // index of the point in the ToF coordinates array

			// Get all point neighbors in a k x k window
			bool valid_point = false;
			for(int x = -k; x < k + 1; x++)
			{
				if (valid_point)
					break;
				for (int y = -k; y < k + 1; y++)
				{
					int idx = (u + x) * width + (v + y);
					if (idx == i) // do not compare the angle between the point with itself
						continue;

					// If the index is not in the point cloud, continue
					if (idx < 0 || idx >= width*height)
						continue;

					// we store in the array for every point 3 values (x,y,z) therefore, we have to convert the indices
					int c_i = i*3;
					int c_idx = idx*3;
					// Get the angle between the lines formed with the viewpoint
					double angle = get_angle_with_viewpoint(
								coordinates[c_i], coordinates[c_i+1], coordinates[c_i+2],
								coordinates[c_idx], coordinates[c_idx+1], coordinates[c_idx+2],
								viewpoint_x, viewpoint_y, viewpoint_z);

					// TODO: remove debug output
					//cout << "x:" << p_x << " x:" << p_y << "  angle:" << angle << endl;
					//if (angle < min_angle || angle > max_angle) // original if condition
					if (angle > min_angle && angle < max_angle)
					{
//						std::cout << coordinates[c_i] << " " << coordinates[c_i+1] << " " << coordinates[c_i+2] << std::endl;
//						std::cout << coordinates[c_idx] << " " << coordinates[c_idx+1] << " " << coordinates[c_idx+2] << std::endl;
						valid_point = true;
						break;
					}
				}
			}
			if (valid_point)
			{
				return false; //  no jump edge
			}
			return true; // point is a jump edge
	}


	/**
	 * Returns a pointer to the first element of the distance image.
	 * The image has the size return from get_size().
	 */
	inline const float* get_distances() const {
		//return reinterpret_cast<const float*> (shm) + sizeof(ToFImageParameters) / sizeof(float);
		return idl_CommToFImage.distances.get_buffer();
	}

	/**
	 * Returns the distance value of a pixel;
	 */
	inline float get_distance(const uint32_t posX, const uint32_t posY, const double unit = 0.001) const {
		const float *srcPtr = get_distances() + (posY * get_width()) + posX;
		return (*srcPtr) / unit;
	}

	inline void set_distances(const float *data) {
		memcpy(idl_CommToFImage.distances.get_buffer(), data, get_image_size() * sizeof(float));
		set_data_valid(true);
	}

	/**
	 * Returns a pointer to the first element of the amplitude image.
	 * The image has the size return from get_size().
	 */
	inline const float* get_amplitudes() const {
		//return reinterpret_cast<const float*> (shm) + (sizeof(ToFImageParameters) + get_image_size()) / sizeof(float);
		return idl_CommToFImage.amplitudes.get_buffer();
	}

	/**
	 * Returns the amplitude value of a pixel;
	 */
	inline float get_amplitude(const uint32_t posX, const uint32_t posY) const {
		const float *srcPtr = get_amplitudes() + (posY * get_width()) + posX;
		return (*srcPtr);
	}

	inline void set_amplitudes(const float *data) {
		memcpy(idl_CommToFImage.amplitudes.get_buffer(), data, get_image_size()  * sizeof(float));
		set_data_valid(true);
	}

	/**
	 * Returns a pointer to the first element of the intensity image.
	 * The image has the size return from get_size().
	 */
	inline const float* get_intensities() const {
		//return reinterpret_cast<const float*> (shm) + (sizeof(ToFImageParameters) + 2 * get_image_size()) / sizeof(float);
		return idl_CommToFImage.intensities.get_buffer();
	}

	/**
	 * Returns the intensity value of a pixel;
	 */
	inline float get_intensity(const uint32_t posX, const uint32_t posY) const {
		const float *srcPtr = get_intensities() + (posY * get_width()) + posX;
		return (*srcPtr);
	}

	inline void set_intensities(const float *data) {
		memcpy(idl_CommToFImage.intensities.get_buffer(), data, get_image_size() * sizeof(float));
		set_data_valid(true);
	}

	/**
	 * Returns a pointer to the first element of the coordinate image.
	 * The image has the size return from get_size() * 3.
	 */
	inline const float* get_coordinates() const {
		//return reinterpret_cast<const float*> (shm) + (sizeof(ToFImageParameters) + 3 * get_image_size()) / sizeof(float);
		return idl_CommToFImage.coordinates.get_buffer();
	}

	inline void set_coordinates(const float *data) {
		memcpy(idl_CommToFImage.coordinates.get_buffer(), data, get_image_size() * sizeof(float) * 3);
		set_data_valid(true);
	}

	/**
	 * Returns a pointer to the first element of the data.
	 * The hole data has the size: get_size();
	 */
	/*
	inline const void* get_data() const {
		return ...shm...;
	}
	*/

	/**
	 * Get the Cartesian 3d point in the sensor coordinate system.
	 */
	inline void get_cartesian_point_sensor(const uint32_t posX, const uint32_t posY, double& x, double& y, double& z,
			const double unit = 0.001) const {

		// get pointer to source position
		const float *srcPtr = get_coordinates() + (posY * get_width() * 3) + posX * 3;

		x = (*srcPtr) / unit;
		y = (*(srcPtr + 1)) / unit;
		z = (*(srcPtr + 2)) / unit;
	}

	/**
	 * Get the Cartesian 3d point in the robot coordinate system.
	 */
	inline void get_cartesian_point_robot(const uint32_t posX, const uint32_t posY, double& x, double& y, double& z,
			const double unit = 0.001) {

		if (robot_mat.n_cols == 0) {
			robot_mat = get_sensor_pose().getHomogeneousMatrix(1);
		}

		// get pointer to source position
		const float *srcPtr = get_coordinates() + (posY * get_width() * 3) + posX * 3;

		arma::vec point(4);

		point[0] = (*srcPtr);
		point[1] = (*(srcPtr + 1));
		point[2] = (*(srcPtr + 2));
		point[3] = 1;
		point = robot_mat * point;

		x = point[0] / unit;
		y = point[1] / unit;
		z = point[2] / unit;
	}

	/**
	 * Get the Cartesian 3d point in the world coordinate system.
	 */
	inline void get_cartesian_point_world(const uint32_t posX, const uint32_t posY, double& x, double& y, double& z,
			const double unit = 0.001) {

		if (world_mat.n_cols == 0) {
			arma::mat pose = get_sensor_pose().getHomogeneousMatrix(1);
			arma::mat pose_robot = get_base_state().get_base_position().get_base_pose3d().getHomogeneousMatrix(1);

			world_mat = pose_robot * pose;
		}

		// get pointer to source position
		const float *srcPtr = get_coordinates() + (posY * get_width() * 3) + posX * 3;

		arma::vec point(4);

		point[0] = (*srcPtr);
		point[1] = (*(srcPtr + 1));
		point[2] = (*(srcPtr + 2));
		point[3] = 1;
		point = world_mat * point;

		x = point[0] / unit;
		y = point[1] / unit;
		z = point[2] / unit;
	}

	/**
	 *  Get the spherical coordinate of a 3d point in the sensor coordinate system.
	 */
	inline void get_spherical_point_sensor(const uint32_t posX, const uint32_t posY, double &radius, double &phi,
			double &theta, const double unit = 0.001) {

		double x, y, z;
		get_cartesian_point_sensor(posX, posY, x, y, z, unit);

		// calculate the spherical coordinates
		radius = sqrt(pow(x, 2) + pow(y, 2) + pow(z, 2));
		phi = atan2(y, x);
		theta = acos(z / radius);

	}

	/**
	 *  Get the spherical coordinate of a 3d point in the robot coordinate system.
	 */
	inline void get_spherical_point_robot(const uint32_t posX, const uint32_t posY, double &radius, double &phi,
			double &theta, const double unit = 0.001) {

		double x, y, z;
		get_cartesian_point_robot(posX, posY, x, y, z, unit);

		// calculate the spherical coordinates
		radius = sqrt(pow(x, 2) + pow(y, 2) + pow(z, 2));
		phi = atan2(y, x);
		theta = acos(z / radius);

	}

	/**
	 *  Get the spherical coordinate of a 3d point in the world coordinate system.
	 */
	inline void get_spherical_point_world(const uint32_t posX, const uint32_t posY, double &radius, double &phi,
			double &theta, const double unit = 0.001) {

		double x, y, z;
		get_cartesian_point_world(posX, posY, x, y, z, unit);

		// calculate the spherical coordinates
		radius = sqrt(pow(x, 2) + pow(y, 2) + pow(z, 2));
		phi = atan2(y, x);
		theta = acos(z / radius);

	}



	/**
	 * Set the pose of the sensor relative to the robot coordinate system.
	 */
	inline void set_sensor_pose(const CommBasicObjects::CommPose3d& pose) {
		//reinterpret_cast<ToFImageParameters*> (shm)->sensor_pose.set_idl(pose.get_idl());
		idl_CommToFImage.sensor_pose = pose.get_idl();
	}

	/**
	 * Set the state of the base.
	 */
	inline void set_base_state(const CommBasicObjects::CommBaseState& state) {
		//reinterpret_cast<ToFImageParameters*> (shm)->base_state.set_idl(state.get_idl());
		idl_CommToFImage.baseState = state.get_idl();
	}

	/**
	 * Set the minimal distance the sensor works.
	 */
	inline void set_min_distance(const double_t value, const double_t unit = 0.001) {
		//reinterpret_cast<ToFImageParameters*> (shm)->min_distance = value * unit * 1000;
		idl_CommToFImage.min_distance = value * unit * 1000;
	}

	/**
	 * Set the maximal distance the sensor works.
	 */
	inline void set_max_distance(const double_t value, const double_t unit = 0.001) {
		//reinterpret_cast<ToFImageParameters*> (shm)->max_distance = value * unit * 1000;
		idl_CommToFImage.max_distance = value * unit * 1000;
	}

	/**
	 * Set the opening angle of the camera in x-axis [rad].
	 * It is expected that the opening angle in positive and negative direction is the same.
	 */
	inline void set_opening_angle_x_axis(const double_t value) {
		//reinterpret_cast<ToFImageParameters*> (shm)->opening_angle_x_axis = value;
		idl_CommToFImage.opening_angle_x_axis = value;
	}

	/**
	 * Set the opening angle of the camera in y-axis [rad].
	 * It is expected that the opening angle in positive and negative direction is the same.
	 */
	inline void set_opening_angle_y_axis(const double_t value) {
		//reinterpret_cast<ToFImageParameters*> (shm)->opening_angle_y_axis = value;
		idl_CommToFImage.opening_angle_y_axis = value;
	}

	/**
	 * Set the integration time which was used for capturing the image.
	 */
	inline void set_integration_time(const double_t value) {
		//reinterpret_cast<ToFImageParameters*> (shm)->integration_time = value;
		idl_CommToFImage.integration_time = value;
	}

	/**
	 * Set the modulation frequency which was used for capturing the image.
	 */
	inline void set_modulation_frequency(const double_t value) {
		idl_CommToFImage.modulation_frequency = value;
	}


	void set_parameters(unsigned int width, unsigned int height) {
		idl_CommToFImage.distances.length(width * height);
		idl_CommToFImage.amplitudes.length(width * height);
		idl_CommToFImage.intensities.length(width * height);
		idl_CommToFImage.coordinates.length(width * height * 3);

		idl_CommToFImage.parameter.width = width;
		idl_CommToFImage.parameter.height = height;
		idl_CommToFImage.parameter.image_size = width * height;// * sizeof(float); // size in bytes
		idl_CommToFImage.min_distance = 0;
		idl_CommToFImage.max_distance = 0;
		idl_CommToFImage.integration_time = 0;
		idl_CommToFImage.modulation_frequency = 0;
		idl_CommToFImage.opening_angle_x_axis = 0;
		idl_CommToFImage.opening_angle_y_axis = 0;
		idl_CommToFImage.is_valid = false;
		idl_CommToFImage.seq_count = 0;

	}


	/**
	 Save an XML like representation of this tof image to the given output stream.
	 */
	void save_xml(std::ostream &os, const std::string &indent = "") const;

protected:
	static const double_t SQRT_EIGHT = 2.828427125;
	static const uint32_t NUMBER_OF_IMAGES = 6;

private:
	inline double get_angle_with_viewpoint(float px, float py, float pz, float qx, float qy, float qz, float vp_x = 0, float vp_y = 0, float vp_z = 0) const
	{
		double dir_a[3], dir_b[3];
		dir_a[0] = vp_x - px;
		dir_a[1] = vp_y - py;
		dir_a[2] = vp_z - pz;
		dir_b[0] = qx - px;
		dir_b[1] = qy - py;
		dir_b[2] = qz - pz;

		// sqrt (sqr (x) + sqr (y) + sqr (z))
		double norm_a = sqrt(dir_a[0] * dir_a[0] + dir_a[1] * dir_a[1] + dir_a[2] * dir_a[2]);

		// Check for bogus 0,0,0 points
		if (norm_a == 0)
			return (0);

		double norm_b = sqrt(dir_b[0] * dir_b[0] + dir_b[1] * dir_b[1] + dir_b[2]* dir_b[2]);
		if (norm_b == 0)
			return (0);

		// dot_product (x, y)
		double dot_pr = dir_a[0] * dir_b[0] + dir_a[1] * dir_b[1] + dir_a[2]* dir_b[2];
		if (dot_pr != dot_pr) // Check for NaNs
			return (0);

		return (acos(dot_pr / (norm_a * norm_b)) * 180.0 / M_PI);
	}


};

}
#endif
